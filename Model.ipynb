{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS8Y_rWBtRio"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models, Input, Model\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Lambda, Reshape\n",
        "\n",
        "# ----------------- Squash Function for Capsules -----------------\n",
        "epsilon = 1e-7\n",
        "def squash(vectors, axis=-1):\n",
        "    s_squared_norm = tf.reduce_sum(tf.square(vectors), axis=axis, keepdims=True)\n",
        "    scale = s_squared_norm / (1. + s_squared_norm) / tf.sqrt(s_squared_norm + epsilon)\n",
        "    return scale * vectors\n",
        "\n",
        "class CapsuleLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_capsule, dim_capsule, routings=3, **kwargs):\n",
        "        super(CapsuleLayer, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_num_capsule = input_shape[1]\n",
        "        self.input_dim_capsule = input_shape[2]\n",
        "        self.W = self.add_weight(\n",
        "            shape=[1, self.input_num_capsule, self.num_capsule, self.input_dim_capsule, self.dim_capsule],\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True,\n",
        "            name='W')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        inputs_expand = tf.expand_dims(inputs, 2)\n",
        "        inputs_expand = tf.expand_dims(inputs_expand, -1)\n",
        "        W_tiled = tf.tile(self.W, [batch_size, 1, 1, 1, 1])\n",
        "        W_tiled = tf.transpose(W_tiled, [0, 1, 2, 4, 3])\n",
        "        u_hat = tf.matmul(W_tiled, inputs_expand)\n",
        "        u_hat = tf.squeeze(u_hat, axis=-1)\n",
        "        b = tf.zeros_like(u_hat[..., 0])\n",
        "        for i in range(self.routings):\n",
        "            c = tf.nn.softmax(b, axis=2)\n",
        "            c = tf.expand_dims(c, -1)\n",
        "            s = tf.reduce_sum(c * u_hat, axis=5)\n",
        "            v = squash(s)\n",
        "            if i < self.routings - 1:\n",
        "                v_expand = tf.expand_dims(v, 1)\n",
        "                b += tf.reduce_sum(u_hat * v_expand, axis=-1)\n",
        "        return v\n",
        "\n",
        "def PrimaryCaps(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
        "    x = layers.Conv2D(filters=dim_capsule * n_channels, kernel_size=kernel_size,\n",
        "                      strides=strides, padding=padding, activation='relu')(inputs)\n",
        "    x = Reshape(target_shape=[-1, dim_capsule + 2])(x)\n",
        "\n",
        "\n",
        "# ----------------- Paths and Constants -----------------\n",
        "train_dir = '/kaggle/input/nail-disease-detection-dataset/data/train'\n",
        "val_dir = '/kaggle/input/nail-disease-detection-dataset/data/validation'\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# ----------------- Data Generators -----------------\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest',\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    channel_shift_range=0.1\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# ----------------- Label Info -----------------\n",
        "labels = sorted(os.listdir(train_dir))\n",
        "num_classes = len(labels)\n",
        "\n",
        "# ----------------- Capsule-Integrated Model -----------------\n",
        "def create_caps_model():\n",
        "    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    base_model.trainable = False\n",
        "\n",
        "    inputs = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = layers.Conv2D(256, 3, padding='same', activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = PrimaryCaps(x, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='same')\n",
        "    x = CapsuleLayer(num_capsule=num_classes, dim_capsule=16)(x)\n",
        "    outputs = Lambda(lambda z: tf.sqrt(tf.reduce_sum(tf.square(z), axis=2)))(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_scratch_caps_model():\n",
        "    inputs = Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
        "    x = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "\n",
        "    x = Conv2D(256, 3, activation='relu', padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # PrimaryCaps + Capsule Layer\n",
        "    primary_caps = PrimaryCaps(x, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='same')\n",
        "    digit_caps = CapsuleLayer(num_capsule=num_classes, dim_capsule=16)(primary_caps)\n",
        "    output = Lambda(lambda z: tf.sqrt(tf.reduce_sum(tf.square(z), axis=2)))(digit_caps)\n",
        "\n",
        "    model = Model(inputs, output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0003),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# ----------------- Generators -----------------\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    directory=val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# ----------------- Train -----------------\n",
        "model = create_caps_model()\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator\n",
        ")\n",
        "\n",
        "# ----------------- Evaluate -----------------\n",
        "val_loss, val_accuracy = model.evaluate(val_generator)\n",
        "print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_accuracy:.4f}\")"
      ]
    }
  ]
}